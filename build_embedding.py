import json
import numpy as np
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import faiss

def build_rag_index(
    jsonl_path="rag_all.jsonl",
    index_path="rag_index.faiss",
    embeddings_path="rag_embeddings.npy",
    model_name="BAAI/bge-m3"
):
    # 1ï¸âƒ£ åŠ è½½æ¨¡å‹
    print(f"ğŸ”¹ Loading embedding model: {model_name}")
    model = SentenceTransformer(model_name,cache_folder='./model')

    # 2ï¸âƒ£ è¯»å–æ–‡æœ¬æ•°æ®
    print(f"ğŸ“– Reading chunks from {jsonl_path}")
    texts, metadata = [], []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            item = json.loads(line)
            texts.append(item["text"])
            metadata.append(item["metadata"])

    # 3ï¸âƒ£ ç”ŸæˆåµŒå…¥
    print(f"âš™ï¸ Generating embeddings for {len(texts)} chunks...")
    embeddings = model.encode(
        texts,
        batch_size=16,
        show_progress_bar=True,
        normalize_embeddings=True
    )

    # 4ï¸âƒ£ ä¿å­˜å‘é‡
    np.save(embeddings_path, embeddings)
    print(f"ğŸ’¾ Embeddings saved to {embeddings_path}")

    # 5ï¸âƒ£ å»ºç«‹ FAISS ç´¢å¼•
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)  # å†…ç§¯ç›¸ä¼¼åº¦ï¼ˆBGE å·²ç»æ˜¯ normalizedï¼‰
    index.add(embeddings.astype(np.float32))
    faiss.write_index(index, index_path)
    print(f"âœ… FAISS index saved to {index_path}")

    return index, metadata


if __name__ == "__main__":
    build_rag_index()