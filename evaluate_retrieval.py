# -*- coding: utf-8 -*-
"""
RAG Retrieval Evaluation Script - Refactored
==========================================
"""

import json
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
from rag_evaluator import evaluate
from typing import Dict, List


# ==================== åŠ è½½æ•°æ® ====================
print("ğŸ”¹ Loading model and data...")
model = SentenceTransformer("BAAI/bge-m3", cache_folder='./model')
index = faiss.read_index("rag_index.faiss")

with open("rag_all.jsonl", "r", encoding="utf-8") as f:
    data = [json.loads(line) for line in f]

with open("arxiv_paper.json", "r", encoding="utf-8") as f:
    arxiv_questions = json.load(f)

with open("github_readme.json", "r", encoding="utf-8") as f:
    github_questions = json.load(f)

all_questions = arxiv_questions + github_questions
print(f"âœ… Loaded {len(all_questions)} test questions\n")


# ==================== å‡†å¤‡è¯„ä¼°æ•°æ® ====================
def prepare_evaluation_data(questions: List[Dict]) -> tuple:
    """
    æ„å»ºè¯„ä¼°æ•°æ®ç»“æ„
    
    âœ… æ”¹è¿›:
    1. æ ¹æ®åŒ¹é…çš„reference_contentæ•°é‡è¿›è¡Œåˆ†çº§æ‰“åˆ†
    2. å»é™¤åœç”¨è¯,æé«˜å…³é”®è¯åŒ¹é…å‡†ç¡®æ€§
    3. æ”¯æŒå¤šreference_contentçš„è¦†ç›–ç‡è¯„ä¼°
    """
    
    # å®šä¹‰åœç”¨è¯
    STOPWORDS = {
        'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'of', 'in', 'to', 'for', 'and', 'or', 'but', 'with', 'by', 'at',
        'from', 'as', 'on', 'this', 'that', 'these', 'those', 'it', 'its'
    }
    
    queries = {}
    gold_paper = {}
    gold_passage = {}
    
    for idx, q in enumerate(questions):
        if "question" not in q:
            continue
            
        qid = f"q{idx}"
        question = q["question"]
        ref_contents = q.get("reference_content", [])
        source_file = q["file"]
        
        # æ·»åŠ  key_terms ç”¨äº HasAnswer è¯„ä¼°
        queries[qid] = {
            "query": question,
            "key_terms": ref_contents  # ç”¨äºè¯„ä¼°,ä¸ç”¨äºæ£€ç´¢
        }
        
        gold_paper[qid] = {}
        gold_passage[qid] = {}
        
        # æ ‡è®°ç›¸å…³æ–‡æ¡£å’Œæ®µè½
        for chunk_idx, chunk in enumerate(data):
            meta = chunk["metadata"]
            chunk_file = meta.get("filename", "")
            chunk_id = f"chunk_{chunk_idx}"
            paper_id = chunk_file
            
            # æ–‡ä»¶ååŒ¹é… = ç›¸å…³
            if source_file in chunk_file or chunk_file in source_file:
                if paper_id not in gold_paper[qid]:
                    gold_paper[qid][paper_id] = 3
                
                # âœ… æ”¹è¿›çš„å†…å®¹åŒ¹é…é€»è¾‘
                if ref_contents:
                    chunk_text = chunk["text"].lower()
                    
                    # æ–¹æ³•1: ç²¾ç¡®çŸ­è¯­åŒ¹é…
                    exact_matches = sum(
                        1 for ref in ref_contents 
                        if ref.lower() in chunk_text
                    )
                    
                    if exact_matches > 0:
                        # æœ‰ç²¾ç¡®åŒ¹é…,æ ¹æ®åŒ¹é…æ•°é‡æ‰“åˆ†
                        total_refs = len(ref_contents)
                        coverage = exact_matches / total_refs
                        
                        if coverage >= 0.8:
                            gold_passage[qid][chunk_id] = 3  # â­â­â­ é«˜åº¦ç›¸å…³
                        elif coverage >= 0.5:
                            gold_passage[qid][chunk_id] = 3  # â­â­â­ ä¸­é«˜åº¦ç›¸å…³
                        else:
                            gold_passage[qid][chunk_id] = 2  # â­â­ ä¸­åº¦ç›¸å…³
                        continue
                    
                    # æ–¹æ³•2: å…³é”®è¯åŒ¹é… (å»é™¤åœç”¨è¯)
                    keyword_matches = 0
                    
                    for ref in ref_contents:
                        # æå–å®ä½“è¯ (é•¿åº¦>3, éåœç”¨è¯)
                        keywords = [
                            w for w in ref.lower().split() 
                            if len(w) > 3 and w not in STOPWORDS
                        ]
                        
                        if not keywords:
                            continue
                        
                        # è®¡ç®—å…³é”®è¯è¦†ç›–ç‡
                        chunk_tokens = set(chunk_text.split())
                        matched_keywords = sum(
                            1 for kw in keywords 
                            if kw in chunk_tokens
                        )
                        
                        keyword_coverage = matched_keywords / len(keywords)
                        
                        # å¦‚æœ40%ä»¥ä¸Šå…³é”®è¯åŒ¹é…,è®¤ä¸ºè¯¥referenceè¢«è¦†ç›–
                        if keyword_coverage >= 0.4:
                            keyword_matches += 1
                    
                    # æ ¹æ®åŒ¹é…çš„referenceæ•°é‡æ‰“åˆ†
                    if keyword_matches > 0:
                        total_refs = len(ref_contents)
                        coverage = keyword_matches / total_refs
                        
                        if coverage >= 0.6:
                            gold_passage[qid][chunk_id] = 3  # â­â­â­ é«˜åº¦ç›¸å…³
                        elif coverage >= 0.3:
                            gold_passage[qid][chunk_id] = 2  # â­â­ ä¸­åº¦ç›¸å…³
                        else:
                            gold_passage[qid][chunk_id] = 1  # â­ ä½åº¦ç›¸å…³
                    else:
                        gold_passage[qid][chunk_id] = 1  # â­ æ¥è‡ªæ­£ç¡®æ–‡æ¡£ä½†å†…å®¹ä¸åŒ¹é…
                else:
                    gold_passage[qid][chunk_id] = 2  # â­â­ æ— reference_content
    
    return queries, gold_paper, gold_passage


# ==================== æ£€ç´¢å‡½æ•° ====================
def retrieve_for_query(query: str, top_k: int = 10) -> List[Dict]:
    """æ‰§è¡ŒFAISSæ£€ç´¢"""
    query_vec = model.encode([query], normalize_embeddings=True)
    D, I = index.search(query_vec.astype(np.float32), top_k)
    
    results = []
    for rank, (idx, score) in enumerate(zip(I[0], D[0])):
        if idx < 0 or idx >= len(data):
            continue
            
        chunk = data[idx]
        meta = chunk["metadata"]
        
        results.append({
            "paper_id": meta.get("filename", "unknown"),
            "chunk_id": f"chunk_{idx}",
            "score": float(score),
            "text": chunk["text"],
            "rank": rank + 1
        })
    
    return results


# ==================== è¿è¡Œè¯„ä¼° ====================
print("ğŸ” Preparing evaluation data...")
queries, gold_paper, gold_passage = prepare_evaluation_data(all_questions)

print(f"âœ… Prepared {len(queries)} queries")
print(f"   - Paper labels: {sum(len(v) for v in gold_paper.values())}")
print(f"   - Passage labels: {sum(len(v) for v in gold_passage.values())}")

# âœ… æ–°å¢: æ˜¾ç¤ºç›¸å…³æ€§åˆ†å¸ƒ
passage_relevance_dist = {}
for qid in gold_passage:
    for chunk_id, score in gold_passage[qid].items():
        passage_relevance_dist[score] = passage_relevance_dist.get(score, 0) + 1

print(f"   - Passage relevance distribution:")
for score in sorted(passage_relevance_dist.keys(), reverse=True):
    print(f"     Score {score}: {passage_relevance_dist[score]} chunks")
print()

if len(queries) == 0:
    print("âŒ No valid queries found!")
    exit(1)

print("ğŸ” Running retrieval...")
runs = {}
for qid, q_data in queries.items():
    runs[qid] = retrieve_for_query(q_data["query"], top_k=10)

print(f"âœ… Retrieved results for {len(runs)} queries\n")

print("ğŸ“Š Evaluating...")
results = evaluate(
    queries=queries,
    runs=runs,
    gold_paper=gold_paper,
    gold_passage=gold_passage,
    k_list=[1, 3, 5, 10],
    bootstrap=True,
    bootstrap_iters=1000
)

# ==================== è¾“å‡ºç»“æœ ====================
print("\n" + "=" * 80)
print("ğŸ“ˆ EVALUATION RESULTS")
print("=" * 80)

print("\nğŸ“Š Macro-Averaged Metrics:\n")

# âœ… ç²¾ç®€çš„æŒ‡æ ‡åˆ†ç»„
metric_groups = {
    "ğŸ“„ Document Retrieval": [
        "paper_mrr@10",
        "paper_ndcg@5", 
        "paper_r@10"
    ],
    "ğŸ“‘ Passage Retrieval": [
        "passage_ndcg@5",
        "passage_p@5"
    ],
    "âœ… Answer Quality": [
        "has_answer@5",
        "answer_coverage@5"
    ],
    "ğŸ¯ Overall Quality": [
        "cite_then_quote@5",
        "diversity@5"
    ]
}

for group_name, metric_list in metric_groups.items():
    print(f"\n{group_name}:")
    
    for metric_name in metric_list:
        if metric_name in results["macro"]:
            values = results["macro"][metric_name]
            mean = values["mean"]
            if "ci95" in values:
                ci_lo, ci_hi = values["ci95"]
                print(f"  {metric_name:25s}: {mean:.4f}  (95% CI: [{ci_lo:.4f}, {ci_hi:.4f}])")
            else:
                print(f"  {metric_name:25s}: {mean:.4f}")

print("\n" + "-" * 80)
print("\nğŸ“‹ Sample Query Analysis (q0):\n")

# æ˜¾ç¤ºç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„è¯¦ç»†ç»“æœ
if "q0" in results["per_query"]:
    q0_result = results["per_query"]["q0"]
    q0_query = queries["q0"]
    
    print(f"Query: {q0_query['query']}")
    print(f"Reference contents: {len(q0_query['key_terms'])} items\n")
    
    # âœ… åªæ˜¾ç¤º @5 çš„æ ¸å¿ƒæŒ‡æ ‡
    print("Core Metrics @ k=5:")
    
    # Document Retrieval
    print(f"  ğŸ“„ Paper MRR         : {q0_result['metrics'].get('paper_mrr@5', 0):.2f}")
    print(f"  ğŸ“„ Paper nDCG        : {q0_result['metrics'].get('paper_ndcg@5', 0):.2f}")
    
    # Passage Retrieval
    print(f"  ğŸ“‘ Passage nDCG      : {q0_result['metrics'].get('passage_ndcg@5', 0):.2f}")
    print(f"  ğŸ“‘ Passage Precision : {q0_result['metrics'].get('passage_p@5', 0):.2f}")
    
    # Answer Quality
    if "has_answer@5" in q0_result["metrics"]:
        has_ans = q0_result["metrics"]["has_answer@5"]
        coverage = q0_result["metrics"]["answer_coverage@5"]
        found = int(coverage * len(q0_query['key_terms']))
        total = len(q0_query['key_terms'])
        
        print(f"  âœ… HasAnswer         : {has_ans:.2f}")
        print(f"  âœ… Answer Coverage   : {coverage:.2f}  ({found}/{total} references found)")
    
    # Overall Quality
    print(f"  ğŸ¯ CiteThenQuote     : {q0_result['metrics'].get('cite_then_quote@5', 0):.2f}")
    print(f"  ğŸ¯ Diversity         : {q0_result['metrics'].get('diversity@5', 0):.2f}")

# ==================== ä¿å­˜ç»“æœ ====================
with open("evaluation_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"\nğŸ’¾ Results saved to: evaluation_results.json")
print("=" * 80 + "\n")